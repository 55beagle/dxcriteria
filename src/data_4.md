
# [データ駆動 04] データ処理パイプライン 

## なぜ、重要か。
データ分析基盤から取得したデータをもとに機械学習や統計処理を利用したアプリケーションを実装するには、試行錯誤の実験フェーズとは異なる知見が必要になります。例えば、スケールして安定したデータ処理を行うワークフローパイプラインの基盤を作るなどです。

このような一般にMLOps/DataOpsと呼ばれる領域に関わる項目をチェックします。

## チェックリスト 

### メトリクスの計測
+ 分析・開発や運用のバリューストリーム上の各種サイクルタイムを計測しており、継続的に改善しているか。

### 学習と改善
+ データレイクから、モデルの実サービス適用までの一連の流れのパフォーマンスモニタ・自動化・効率化を行うエンジニアリングチームが存在するか。

### プラクティスと習慣
+ データレイクから、データ分析基盤までのETL処理にも自動テストが存在しており、変換エラーなどがモニタリングされているか。
+ 実運用されているデータ分析・学習のための前処理や学習処理を実行するためのワークフロー処理基盤(ETLの一貫性・冪等性・可用性を確保するための基盤)が存在するか。
+ 学習済みのモデルを検証し、サービスインするまでの処理は自動化されているか。

### アンチパターン
+ 週次集計や月次集計の処理が特定の日時に終わることを想定しており、障害が発生した場合にデータが欠損してしまう。
+ 実験時の環境を実サービス環境に向けてポータブルにするためのコンテナ化やIaC(Infrastructure as Code)が存在しない。　
+ データサイエンス/機械学習/データアプリケーションエンジニアリング/クラウドインフラなどの知見が１名に属人化している。
            